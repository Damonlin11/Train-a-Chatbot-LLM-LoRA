{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20072,"status":"ok","timestamp":1688236714681,"user":{"displayName":"Damon Lin","userId":"00585041640467235705"},"user_tz":240},"id":"RhKZjHfCyWvD","outputId":"67a99571-ca60-4def-8f33-59e90dae6dc3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GRSb8jWI_HLf"},"outputs":[],"source":["import os"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_zy8T9AyBogT"},"outputs":[],"source":["\n","os.chdir('/content/train-lora-main')\n","!pip install -r requirements.txt\n","# to do: upload file to modules and training folders\n","!mkdir repositories\n","!mkdir models\n","!mkdir modules\n","os.chdir('/content/train-lora-main/modules')\n","!mkdir pycache\n","# to do: upload files to pycache folder\n","os.chdir('/content/train-lora-main')\n","!mkdir training\n","os.chdir('/content/train-lora-main/training')\n","!mkdir datasets\n","!mkdir formats\n","# to do: upload files to datasets folder\n","\n","#os.chdir('/content')\n","os.chdir('/content/train-lora-main/repositories')\n","!git clone https://github.com/oobabooga/GPTQ-for-LLaMa.git\n","!git clone https://github.com/johnsmith0031/alpaca_lora_4bit.git\n","!pip install -r GPTQ-for-LLaMa/requirements.txt\n","!pip install -r alpaca_lora_4bit/requirements.txt\n","!pip install accelerate -U\n","os.chdir('/content/train-lora-main/repositories/GPTQ-for-LLaMa')\n","!python setup_cuda.py install\n","os.chdir('/content/train-lora-main')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":255745,"status":"ok","timestamp":1688236973365,"user":{"displayName":"Damon Lin","userId":"00585041640467235705"},"user_tz":240},"id":"E8wkZqgJfZrv","outputId":"2dc7f62a-7d50-44ad-8503-385c03a42a17"},"outputs":[],"source":["os.chdir('/content/drive/MyDrive/train-lora-main')\n","!pip install -r requirements.txt\n","os.chdir('/content/drive/MyDrive/train-lora-main/repositories')\n","!git clone https://github.com/oobabooga/GPTQ-for-LLaMa.git\n","!git clone https://github.com/johnsmith0031/alpaca_lora_4bit.git\n","!pip install -r GPTQ-for-LLaMa/requirements.txt\n","!pip install -r alpaca_lora_4bit/requirements.txt\n","!pip install accelerate -U\n","os.chdir('/content/drive/MyDrive/train-lora-main/repositories/GPTQ-for-LLaMa')\n","!python setup_cuda.py install\n","os.chdir('/content/drive/MyDrive/train-lora-main')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":188817,"status":"ok","timestamp":1688237162177,"user":{"displayName":"Damon Lin","userId":"00585041640467235705"},"user_tz":240},"id":"yL-ulXc546wz","outputId":"f1696c30-9b01-469c-fa21-ceba5aef5087"},"outputs":[],"source":["# To Download a model\n","# Note: If use Colab, create a \"models\" folder in the current working directory before runing the code.\n","!python download-model.py TheBloke/vicuna-13B-1.1-GPTQ-4bit-128g"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pI-sax7UMNI5"},"outputs":[],"source":["# train with raw text file\n","!python do_training.py --model TheBloke_vicuna-13B-1.1-GPTQ-4bit-128g --lora_name Goggins_vicuna_13b_GPTQ_raw_full --raw_text_file david_goggins_dataset_full --model_type llama --wbits 4 --groupsize 128 --monkey-patch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rk8f57LLu2o5"},"outputs":[],"source":["# download the model\n","folder_path = '/content/train-lora-main/loras'\n","\n","import zipfile\n","\n","zip_file_name = 'loras.zip'\n","\n","with zipfile.ZipFile(zip_file_name, 'w', zipfile.ZIP_DEFLATED) as zipf:\n","    for root, dirs, files in os.walk(folder_path):\n","        for file in files:\n","            zipf.write(os.path.join(root, file))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OnbQWD_fLZ2R"},"outputs":[],"source":["# download the wandb\n","folder_path = '/content/drive/MyDrive/train-lora-main/models'\n","\n","import zipfile\n","\n","zip_file_name = 'models.zip'\n","\n","with zipfile.ZipFile(zip_file_name, 'w', zipfile.ZIP_DEFLATED) as zipf:\n","    for root, dirs, files in os.walk(folder_path):\n","        for file in files:\n","            zipf.write(os.path.join(root, file))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":362,"status":"ok","timestamp":1687916566094,"user":{"displayName":"Damon Lin","userId":"00585041640467235705"},"user_tz":240},"id":"aMo_0y0dKqy3","outputId":"c4333c2f-7acf-4732-9d81-6fd23e9ab5fa"},"outputs":[{"data":{"application/javascript":"\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":"download(\"download_c5708e71-c21c-46f2-bd19-c58544a0367d\", \"loras.zip\", 97189877)","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"}],"source":["from google.colab import files\n","\n","files.download(zip_file_name)\n","\n","# Alternative: move the zip file to google drive and download from there"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOyTcLyj5beun4xg+L0ziUl","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
